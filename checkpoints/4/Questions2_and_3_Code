2. Given an officer, and the nature of the complaint (TRR details), can we predict the subject identities? What are the most important features?

Make and upload this table in terminal psql cpdb before using databricks:

QUERY:
CREATE TABLE sql_data5 AS SELECT trr_trr.id AS trr_id, officer_rank, beat, officer_on_duty, officer_in_uniform, officer_assigned_beat, trr_datetime, number_of_weapons_discharged, lighting_condition, officer_id, ST_X(ST_TRANSFORM(point,4674)) AS LONG,ST_Y(ST_TRANSFORM(point,4674)) AS LAT, o.gender, o.race, EXTRACT('YEAR' FROM trr_datetime) - o.birth_year FROM trr_trr JOIN data_officer o ON officer_id=o.id;

Export table to CSV:
QUERY:
\copy sql_data5 to '/Users/caseygrage/Downloads/sql_data5.csv' WITH (FORMAT csv);

In python databricks:

Command 1:

# import everything and convert data to dataframes

from pyspark.ml import Pipeline
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.sql.functions import col 
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.ensemble import ExtraTreesClassifier
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cross_validation import ShuffleSplit
from sklearn.metrics import r2_score
from collections import defaultdict
import pandas as pd
from sklearn.metrics import accuracy_score

# Load and parse the data file, converting it to a DataFrame.
trr_subjects_df = sqlContext.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/trr_subjects.txt')
trr_statuses_df = sqlContext.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/trr_statuses.csv'),
trr_weapondischarge_df = sqlContext.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/trr_weapondischarge.csv'), 
officer_profiles_df = sqlContext.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/officer_profiles.csv'),
trr_trr_df = sqlContext.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/trr_trr.csv')
trr_subjectweapon_df = sqlContext.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/trr_subjectweapon.csv')
trr_actionresponse_df = sqlContext.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/trr_actionresponse.csv')
data_officer_df = sqlContext.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/data_officer.csv')
sql_data_df = sqlContext.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/sql_data.csv')

Command 2:

# cache all the dataframes 

# worked after changing to .txt
trr_subjects_df.cache()

# changed to tuples
trr_statuses_df[0].cache()
trr_weapondischarge_df[0].cache()
officer_profiles_df[0].cache()

# normal
sql_data_df.cache()
data_officer_df.cache()
trr_trr_df.cache()
trr_actionresponse_df.cache()
trr_subjectweapon_df.cache()

Command 3:

#create or replace tempviews

sql_data_df.createOrReplaceTempView("sql_data")
data_officer_df.createOrReplaceTempView("data_officer")
trr_trr_df.createOrReplaceTempView("trr_trr")
trr_actionresponse_df.createOrReplaceTempView("trr_actionresponse")
trr_subjectweapon_df.createOrReplaceTempView("trr_subjectweapon")
trr_subjects_df.createOrReplaceTempView("trr_subjects")
officer_profiles_df[0].createOrReplaceTempView("officer_profiles")
trr_statuses_df[0].createOrReplaceTempView("trr_statuses")
trr_weapondischarge_df[0].createOrReplaceTempView("trr_weapondischarge")

Command 4:

# trim variables I don't care about

shortened_officer_profiles_df = officer_profiles_df[0].drop("UID").drop("appointed_date").drop("current_rank").drop("first_name").drop("last_name").drop("tags").drop("middle_initial").drop("suffix_name").drop("resignation_date").drop("complaint_percentile").drop("middle_initial2")
shortened_trr_trr_df = trr_trr_df.drop("block").drop("direction").drop("street").drop("trr_datetime").drop("location_recode").drop("subject_id").drop("subject_birth_year").drop("officer_unit_id").drop("officer_unit_detail_id")
shortened_trr_actionresponse_df = trr_actionresponse_df.drop("person").drop("other_description").drop("member_action")
shortened_trr_subjects_df = trr_subjects_df.drop("subject_no").drop("sr_no").drop("se_no").drop("event_id").drop("subject_ID")
shortened_trr_statuses_df = trr_statuses_df[0].drop("row_id").drop("TRR-statuses_2004-2016_2016-09_ID").drop("UID").drop("old_UID")
# trr_subjectweapon
# trr_weapondischarge

shortened_officer_profiles_df.createOrReplaceTempView("sh_officer_profiles")
shortened_trr_trr_df.createOrReplaceTempView("sh_trr_trr")
shortened_trr_actionresponse_df.createOrReplaceTempView("sh_trr_actionresponse")
trr_actionresponse_df.createOrReplaceTempView("sh_trr_actionresponse")
trr_subjects_df.createOrReplaceTempView("sh_trr_subjects")
shortened_trr_statuses_df.createOrReplaceTempView("sh_trr_statuses")

Command 5:

# create report of all the variables I carea about, parameterize the report, cast all as doubles

final_officer_report_df = spark.sql("SELECT sql_data.trr_id, officer_rank, beat, officer_on_duty='t' AS officer_on_duty, officer_in_uniform='t' AS officer_in_uniform, officer_assigned_beat=beat AS officer_assigned_beat, trr_datetime, number_of_weapons_discharged>0 AS weapon_discharged, lighting_condition, officer_id, lon, lat, officer_gender='M' AS officer_gender, officer_race, officer_age, sub.race AS subject_race, sub.gender='MALE' AS subject_gender FROM sql_data JOIN trr_subjects sub ON sub.trr_id = sql_data.trr_id WHERE officer_race is NOT NULL AND officer_gender is NOT NULL AND sub.race is NOT NULL AND sub.gender is NOT NULL")

# officer_assigned_beat
# officer_in_uniform
# officer_on_duty

final_officer_report_df.printSchema()
final_officer_report_df.cache()
final_officer_report_df.createOrReplaceTempView("final_officer_report")

# display(final_officer_report_df)

foo = spark.sql("""
select * from final_officer_report limit 10
""")

# integer encode rank, lighting condition, oRace, sRace
clarified_report_parameterized = spark.sql("""
SELECT 
    case when coalesce(officer_on_duty, false)=false then 0 else 1 end as officer_on_duty,
    case when coalesce(officer_in_uniform, false)=false then 0 else 1 end as officer_in_uniform,
    case when coalesce(officer_assigned_beat, false)=false then 0 else 1 end as officer_assigned_beat,
    case when coalesce(weapon_discharged, false)=false then 0 else 1 end as weapon_discharged,
    case when coalesce(officer_gender, false)=false then 0 else 1 end as officer_gender,
    int(round(lat, 4)*10000) as lat, 
    int(round(lon, 4)*10000) as lon,
    case
        when officer_race = 'White' then 1
        when officer_race = 'Black' then 2
        when officer_race = 'Hispanic' then 3
        when officer_race = 'Asian/Pacific' then 4
        when officer_race = 'Native American/Alaskan Native' then 5
        else 0
    end as officer_race,
    case
        when lighting_condition = 'DAYLIGHT' then 1
        when lighting_condition = 'DUSK' then 2
        when lighting_condition = 'NIGHT' then 3
        when lighting_condition = 'GOOD ARTIFICIAL' then 4
        when lighting_condition = 'POOR ARTIFICIAL' then 5
        else 0
    end as lighting_condition,
    case
        when officer_rank = 'Lieutenant Of Police' then 1
        when officer_rank = 'Detective' then 2
        when officer_rank = 'Sergeant Of Police' then 3
        when officer_rank = 'Police Officer' then 4
        else 0
    end as officer_rank,
    case
        when officer_age < 25 then 24
        when officer_age >= 25 AND officer_age < 30 then 25
        when officer_age >= 30 AND officer_age < 40 then 30
        when officer_age >= 40 AND officer_age < 55 then 40
        when officer_age >= 55 then 55
        else 0
    end as officer_age,
    case
        when subject_race = 'WHITE' then 1
        when subject_race = 'BLACK' then 2
        when subject_race = 'HISPANIC' then 3
        when subject_race = 'ASIAN/PACIFIC ISLANDER' then 4
        when subject_race = 'NATIVE AMERICAN/ALASKAN NATIVE' then 5
        else 0
    end as subject_race,
    case when coalesce(subject_gender, false)=false then 0 else 1 end as subject_gender
    
    FROM final_officer_report
    WHERE officer_race is NOT NULL AND officer_gender is NOT NULL AND subject_race is NOT NULL AND subject_gender is NOT NULL
""")

# turn everything into numbers
# clarified_report_parameterized = clarified_report_parameterized.select([col(c).cast("double").alias(c) for c in clarified_report_parameterized.columns])

display(clarified_report_parameterized)

Command 6:

# random forest that predicts subject gender

# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html
# http://blog.datadive.net/selecting-good-features-part-iii-random-forests/


# do the random split first to keep the x and y is aligned (as soon as I finish making clarified_report_parameterized)
trainingData1, testData1 = clarified_report_parameterized.randomSplit([0.7, 0.3])
# THEN... with the training set...
# the last two columns (subject_race, subject_gender are the DVs). I can do 3 different things to say how well do my input vectors determine race. How well do my input vectors determine gender, and how well do my input vectors determine race/gender combo. need <-- need 3 random forests
# the training set is all the IVs with the y as the last column. do the same for predicting gender


y1_pred_prepandas = testData1 # to be used to calculate accuracy later

# vector that just predicts gender
x1 = trainingData1.drop("subject_race").drop("subject_gender")
y1 = trainingData1[["subject_gender"]]
print(x1)
print(y1)

                        
# remove the DV from the y test set
# y1 = testData1.drop("subject_gender")
          
x1 = x1.toPandas()
x1 = np.array(x1)
y1 = y1.toPandas()
y1 = np.array(y1)

# # get y answers
# y1_true_list = []
# for i in y1_pred.index:
#   y1_true_list.append(y1_pred.at[i, "subject_gender"])
# y1 = np.array(y1_true_list)

# x1 = x1[:, None] #reshape X 

print("x1")
print(x1.shape)
print(x1)
print("  ")
print("y1")
print(y1.shape)
print(y1)

# make random forest
rfc1 = RandomForestClassifier(n_estimators=500, max_depth=2)
print(rfc1)
rfc1.fit(x1, y1)

Command 7:

# random forest that predicts subject gender

# get feature names
feature_names = list(clarified_report_parameterized)

print("Predict subject_gender given the 11 other features:")
print(rfc1.predict([[1, 0, 0, 0, 1, 419024, -877204, 1, 1, 3, 30]]))
print("")
print("Features sorted by their importance:")
print(sorted(zip(map(lambda x: round(x, 4), rfc1.feature_importances_), feature_names), reverse=True))

# Then print out the y test set WITH the DV and compare that to the predict set.

Command 8:

# random forest that predicts subject race

trainingData2, testData2 = clarified_report_parameterized.randomSplit([0.7, 0.3])

# vector that just predicts gender
x2 = trainingData2.drop("subject_race").drop("subject_gender")
y2 = trainingData2[["subject_race"]]
print(x2)
print(y2)

                        
# remove the DV from the y test set
# y1 = testData1.drop("subject_gender")
          
x2 = x2.toPandas()
x2 = np.array(x2)
y2 = y2.toPandas()
y2 = np.array(y2)

print("x2")
print(x2.shape)
print(x2)
print("  ")
print("y2")
print(y2.shape)
print(y2)

# make random forest
rfc2 = RandomForestClassifier(n_estimators=600, max_depth=2)
print(rfc2)
rfc2.fit(x2, y2)

Command 9:

# random forest that predicts subject race

print("Predict subject_race given the 11 other features:")

print(rfc2.predict([[1, 1, 1, 1, 0, 41.8934, -87.7117, 1, 0, 4, 50]]))
print("")
print("Features importances (not sorted):")
print(rfc2.feature_importances_)
print("")
print("Features sorted by their importance:")
print(sorted(zip(map(lambda x: round(x, 4), rfc2.feature_importances_), feature_names), reverse=True))

Command 10:

# random forest that predicts subject race/gender combo

# Make every combination of race and gender its own integer, then make subject_race_gender its own column 
# each subject race is 10, 20, 30, 40, 50. Gender as we know is 0 or 1. So then just add gender to race

clarified_report_parameterized.createOrReplaceTempView("clarified_report_parameterized_view")

clarified_report_3 = spark.sql("""
SELECT
    officer_on_duty, 
    officer_in_uniform,
    officer_assigned_beat,
    weapon_discharged,
    officer_gender, 
    lat, 
    lon,
    officer_race,
    lighting_condition,
    officer_rank,
    officer_age,
    subject_gender,
    case
        when subject_race = 1 AND subject_gender = 1 then 11
        when subject_race = 1 AND subject_gender = 0 then 10
        when subject_race = 2 AND subject_gender = 1 then 21
        when subject_race = 2 AND subject_gender = 0 then 20
        when subject_race = 3 AND subject_gender = 1 then 31
        when subject_race = 3 AND subject_gender = 0 then 30
        when subject_race = 4 AND subject_gender = 1 then 41
        when subject_race = 4 AND subject_gender = 0 then 40
        when subject_race = 5 AND subject_gender = 1 then 51
        when subject_race = 5 AND subject_gender = 0 then 50
        else 0
    end as subject_race
    FROM clarified_report_parameterized_view
    WHERE officer_race is NOT NULL AND officer_gender is NOT NULL AND subject_race is NOT NULL AND subject_gender is NOT NULL
""")

trainingData3, testData3 = clarified_report_3.randomSplit([0.7, 0.3])
y3_pred_prepandas = testData3 # to be used to calculate accuracy later

# vector that just predicts gender
x3 = trainingData3.drop("subject_race").drop("subject_gender")
y3 = trainingData3[["subject_race"]]
print(x2)
print(y2)

                        
# remove the DV from the y test set
# y1 = testData1.drop("subject_gender")
          
x3 = x3.toPandas()
x3 = np.array(x3)
y3 = y3.toPandas()
y3 = np.array(y3)

print("x3")
print(x3.shape)
print(x3)
print("  ")
print("y3")
print(y3.shape)
print(y3)

# make random forest
rfc3 = RandomForestClassifier(n_estimators=500, max_depth=2)
print(rfc3)
rfc3.fit(x3, y3)

Command 11:

# get feature names
feature_names = list(clarified_report_3)

# random forest that predicts subject race/gender combo

print("Predict subject_race/subject_gender combo given the 11 other features:")

print(rfc3.predict([[1, 1, 0, 0, 1, 41.8934, -87.7117, 1, 1, 4, 30]]))
print("")
print("Features sorted by their importance:")
print(sorted(zip(map(lambda x: round(x, 4), rfc3.feature_importances_), feature_names), reverse=True))



3. Given a subject, and the nature of the complaint (TRR details), can we predict the officer identities? What are the most important features?


Command 12:

# random forest that predicts officer gender

trainingData4, testData4 = clarified_report_parameterized.randomSplit([0.7, 0.3])

y4_pred_prepandas = testData4 # to be used to calculate accuracy later

# vector that just predicts gender
x4 = trainingData1.drop("officer_race").drop("officer_gender").drop("officer_age")
y4 = trainingData1[["officer_gender"]]
print(x4)
print(y4)
         
x4 = x4.toPandas()
x4 = np.array(x4)
y4 = y4.toPandas()
y4 = np.array(y4)

# make random forest
rfc4 = RandomForestClassifier(n_estimators=500, max_depth=2)
print(rfc4)
rfc4.fit(x4, y4)


Command 13:

# random forest that predicts officer gender

# get feature names
feature_names = ["officer_on_duty", "officer_in_uniform", "officer_assigned_beat", "weapon_discharged", "lat", "lon", "lighting_condition", "officer_rank", "subject_race", "subject_gender"]

print("Predict officer_gender given the 10 other features:")
print(rfc4.predict([[1, 0, 0, 0, 419024, -877204, 1, 3, 1, 1]]))
print("")
print("Features sorted by their importance:")
print(sorted(zip(map(lambda x: round(x, 4), rfc4.feature_importances_), feature_names), reverse=True))

# Then print out the y test set WITH the DV and compare that to the predict set.

Command 14:

# random forest that predicts officer race

trainingData5, testData5 = clarified_report_parameterized.randomSplit([0.7, 0.3])

y5_pred_prepandas = testData5 # to be used to calculate accuracy later

# vector that just predicts gender
x5 = trainingData5.drop("officer_race").drop("officer_gender").drop("officer_age")
y5 = trainingData5[["officer_race"]]
print(x5)
print(y5)
         
x5 = x5.toPandas()
x5 = np.array(x5)
y5 = y5.toPandas()
y5 = np.array(y5)

# make random forest
rfc5 = RandomForestClassifier(n_estimators=500, max_depth=2)
print(rfc5)
rfc5.fit(x5, y5)

Command 15:

# random forest that predicts officer race

# get feature names
feature_names = ["officer_on_duty", "officer_in_uniform", "officer_assigned_beat", "weapon_discharged", "lat", "lon", "lighting_condition", "officer_rank", "subject_race", "subject_gender"]

print("Predict officer_race given the 10 other features:")
print(rfc5.predict([[1, 0, 0, 0, 419024, -877204, 1, 3, 1, 1]]))
print("")
print("Features sorted by their importance:")
print(sorted(zip(map(lambda x: round(x, 4), rfc5.feature_importances_), feature_names), reverse=True))

# Then print out the y test set WITH the DV and compare that to the predict set. 


Command 16:

# random forest that predicts officer race/gender combo

# Make every combination of race and gender its own integer, then make subject_race_gender its own column 
# each subject race is 10, 20, 30, 40, 50. Gender as we know is 0 or 1. So then just add gender to race

clarified_report_parameterized.createOrReplaceTempView("clarified_report_parameterized_view")

clarified_report_4 = spark.sql("""
SELECT
    officer_on_duty, 
    officer_in_uniform,
    officer_assigned_beat,
    weapon_discharged,
    lat, 
    lon,
    lighting_condition,
    officer_rank,
    subject_race,
    subject_gender,
    case
        when officer_race = 1 AND officer_gender = 1 then 11
        when officer_race = 1 AND officer_gender = 0 then 10
        when officer_race = 2 AND officer_gender = 1 then 21
        when officer_race = 2 AND officer_gender = 0 then 20
        when officer_race = 3 AND officer_gender = 1 then 31
        when officer_race = 3 AND officer_gender = 0 then 30
        when officer_race = 4 AND officer_gender = 1 then 41
        when officer_race = 4 AND officer_gender = 0 then 40
        when officer_race = 5 AND officer_gender = 1 then 51
        when officer_race = 5 AND officer_gender = 0 then 50
        else 0
    end as officer_race
    FROM clarified_report_parameterized_view
    WHERE officer_race is NOT NULL AND officer_gender is NOT NULL AND subject_race is NOT NULL AND subject_gender is NOT NULL
""")

trainingData6, testData6 = clarified_report_4.randomSplit([0.7, 0.3])
y6_pred_prepandas = testData6 # to be used to calculate accuracy later

# vector that just predicts gender
x6 = trainingData6.drop("officer_race").drop("officer_gender").drop("officer_age")
y6 = trainingData6[["officer_race"]]
print(x6)
print(y6)

                        
# remove the DV from the y test set
# y1 = testData1.drop("subject_gender")
          
x6 = x6.toPandas()
x6 = np.array(x6)
y6 = y6.toPandas()
y6 = np.array(y6)

# make random forest
rfc6 = RandomForestClassifier(n_estimators=500, max_depth=2)
print(rfc6)
rfc6.fit(x6, y6)


Command 17:

# random forest that predicts officer race

# get feature names
feature_names = ["officer_on_duty", "officer_in_uniform", "officer_assigned_beat", "weapon_discharged", "lat", "lon", "lighting_condition", "officer_rank", "subject_race", "subject_gender"]

print("Predict officer_race/gender combo given the 10 other features:")
print(rfc6.predict([[1, 0, 0, 0, 419024, -877204, 1, 3, 1, 1]]))
print("")
print("Features sorted by their importance:")
print(sorted(zip(map(lambda x: round(x, 4), rfc6.feature_importances_), feature_names), reverse=True))

# Then print out the y test set WITH the DV and compare that to the predict set.
